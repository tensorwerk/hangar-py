{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hangar Quick Start Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will guide you on working with the basics of Hangar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install Hangar via `pip`:\n",
    "\n",
    "```bash\n",
    "pip install hangar\n",
    "```\n",
    "\n",
    "or via `conda`:\n",
    "```bash\n",
    "conda install -c conda-forge hangar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other requirements:\n",
    "* pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And just start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hangar import Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create and initialize a `Repository`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the folder where you want to store the Hangar `Repository`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir /Volumes/Archivio/tensorwerk/hangar/imagenette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and create the `Repository` object. Note that when you specify a new folder for a Hangar repository, Python shows you a warning saying that you will need to initialize the repo before starting working on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/hangar-nested/lib/python3.7/site-packages/hangar-0.5.0.dev1-py3.7-macosx-10.9-x86_64.egg/hangar/context.py:94: UserWarning: No repository exists at /Volumes/Archivio/tensorwerk/hangar/imagenette/.hangar, please use `repo.init()` method\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "repo = Repository(path='/Volumes/Archivio/tensorwerk/hangar/imagenette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hangar Repo initialized at: /Volumes/Archivio/tensorwerk/hangar/imagenette/.hangar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Volumes/Archivio/tensorwerk/hangar/imagenette/.hangar'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.init(user_name='Alessia Marcolini', user_email='alessia@tensorwerk.com', remove_old=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Repository checkout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Repository` can be checked out in two modes: write-enabled and read-only. We need to checkout the repo in write mode in order to initialize the arraysets and write into them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = repo.checkout(write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A checkout allows access to `columns` and `metadata`. The `columns` and `metadata` attributes of a checkout provide the interface to working with all of the data on disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hangar Columns                \n",
       "    Writeable         : True                \n",
       "    Number of Columns : 0                \n",
       "    Column Names / Partial Remote References:                \n",
       "      - "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hangar Metadata                \n",
       "    Writeable: True                \n",
       "    Number of Keys: 0\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Download and prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start playing with Hangar, let's get some data to work on. We'll be using the [Imagenette dataset](https://github.com/fastai/imagenette)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-09 15:11:17--  https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
      "Resolving s3.amazonaws.com... 52.217.42.134\n",
      "Connecting to s3.amazonaws.com|52.217.42.134|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 98948031 (94M) [application/x-tar]\n",
      "Saving to: ‘imagenette2-160.tgz’\n",
      "\n",
      "imagenette2-160.tgz 100%[===================>]  94.36M  2.37MB/s    in 49s     \n",
      "\n",
      "2020-03-09 15:12:08 (1.92 MB/s) - ‘imagenette2-160.tgz’ saved [98948031/98948031]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -xzf imagenette2-160.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download `words.txt` to get the corrispondence between ImageNet synset name and a human readable label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-09 15:12:45--  http://image-net.org/archive/words.txt\n",
      "Resolving image-net.org... 171.64.68.16\n",
      "Connecting to image-net.org|171.64.68.16|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2655750 (2.5M) [text/plain]\n",
      "Saving to: ‘imagenette2-160/words.txt’\n",
      "\n",
      "words.txt           100%[===================>]   2.53M   728KB/s    in 3.6s    \n",
      "\n",
      "2020-03-09 15:12:50 (728 KB/s) - ‘imagenette2-160/words.txt’ saved [2655750/2655750]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget http://image-net.org/archive/words.txt -P imagenette2-160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dataset_dir = Path('imagenette2-160')\n",
    "\n",
    "synset_label = {}\n",
    "\n",
    "with open(dataset_dir / 'words.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        synset, label = line.split('\\t')\n",
    "        synset_label[synset] = label.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.60s/it]\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for synset in tqdm(os.listdir(dataset_dir / 'train')):\n",
    "    label = synset_label[synset]\n",
    "    \n",
    "    for image_filename in os.listdir(dataset_dir / 'train' / synset):\n",
    "        image = Image.open(dataset_dir / 'train' / synset / image_filename)\n",
    "        image = image.resize((163, 160))\n",
    "        data = asarray(image)\n",
    "        \n",
    "        if len(data.shape) == 2:\n",
    "            continue\n",
    "        \n",
    "        train_images.append(data)\n",
    "        train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9296, 160, 163, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.80it/s]\n"
     ]
    }
   ],
   "source": [
    "val_images = []\n",
    "val_labels = []\n",
    "\n",
    "for synset in tqdm(os.listdir(dataset_dir / 'val')):\n",
    "    label = synset_label[synset]\n",
    "    \n",
    "    for image_filename in os.listdir(dataset_dir / 'val' / synset):\n",
    "        image = Image.open(dataset_dir / 'val' / synset / image_filename)\n",
    "        image = image.resize((163, 160))\n",
    "        data = asarray(image)\n",
    "        \n",
    "        if len(data.shape) == 2:\n",
    "                continue\n",
    "            \n",
    "        val_images.append(data)\n",
    "        val_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = np.array(val_images)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3856, 160, 163, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (hangar-nested)",
   "language": "python",
   "name": "hangar-nested"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
